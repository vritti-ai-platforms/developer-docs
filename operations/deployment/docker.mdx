---
title: 'Docker Setup'
description: 'Docker configuration for local development and production deployment'
---

## Overview

This guide covers Docker configuration for the Vritti platform, including local development setup with Docker Compose and production-ready Dockerfiles for both backend (NestJS) and frontend (RSBuild) applications.

## Local Development

### Database with Docker Compose

The backend uses a simple Docker Compose configuration for local PostgreSQL development.

<CodeGroup>

```yaml local-db-compose.yml
version: '1.0'
services:
  postgres:
    image: postgres:17
    container_name: vritti-postgres-17
    restart: unless-stopped
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: localdev
      POSTGRES_DB: saas_db
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  pgdata:
```

</CodeGroup>

### Starting the Local Database

```bash
# Start PostgreSQL
pnpm db:start

# Stop PostgreSQL
pnpm db:stop

# Or using docker compose directly
docker compose -f local-db-compose.yml up -d
docker compose -f local-db-compose.yml down
```

<Note>
The database data is persisted in the `pgdata` volume, so your data survives container restarts.
</Note>

## Production Dockerfiles

### Backend Dockerfile (NestJS)

A multi-stage build optimized for production NestJS applications.

<CodeGroup>

```dockerfile Dockerfile.backend
# =============================================================================
# Stage 1: Dependencies
# =============================================================================
FROM node:22-alpine AS deps

# Install pnpm
RUN corepack enable && corepack prepare pnpm@latest --activate

WORKDIR /app

# Copy package files
COPY package.json pnpm-lock.yaml ./

# Install all dependencies (including devDependencies for build)
RUN pnpm install --frozen-lockfile

# =============================================================================
# Stage 2: Builder
# =============================================================================
FROM node:22-alpine AS builder

RUN corepack enable && corepack prepare pnpm@latest --activate

WORKDIR /app

# Copy dependencies from deps stage
COPY --from=deps /app/node_modules ./node_modules
COPY . .

# Build the NestJS application
RUN pnpm build

# Prune devDependencies for production
RUN pnpm prune --prod

# =============================================================================
# Stage 3: Production Runner
# =============================================================================
FROM node:22-alpine AS runner

# Add non-root user for security
RUN addgroup --system --gid 1001 nodejs && \
    adduser --system --uid 1001 nestjs

WORKDIR /app

# Set production environment
ENV NODE_ENV=production

# Copy only necessary files from builder
COPY --from=builder --chown=nestjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nestjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nestjs:nodejs /app/package.json ./package.json

# Switch to non-root user
USER nestjs

# Expose the application port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:3000/health || exit 1

# Start the application
CMD ["node", "dist/main"]
```

</CodeGroup>

### Frontend Dockerfile (RSBuild + Nginx)

A multi-stage build for the RSBuild React application served via Nginx.

<CodeGroup>

```dockerfile Dockerfile.frontend
# =============================================================================
# Stage 1: Dependencies
# =============================================================================
FROM node:22-alpine AS deps

RUN corepack enable && corepack prepare pnpm@latest --activate

WORKDIR /app

# Copy package files
COPY package.json pnpm-lock.yaml ./

# Install dependencies
RUN pnpm install --frozen-lockfile

# =============================================================================
# Stage 2: Builder
# =============================================================================
FROM node:22-alpine AS builder

RUN corepack enable && corepack prepare pnpm@latest --activate

WORKDIR /app

# Copy dependencies
COPY --from=deps /app/node_modules ./node_modules
COPY . .

# Build arguments for environment-specific builds
ARG VITE_API_URL
ARG VITE_APP_ENV=production

ENV VITE_API_URL=$VITE_API_URL
ENV VITE_APP_ENV=$VITE_APP_ENV

# Build the application
RUN pnpm build

# =============================================================================
# Stage 3: Production Server (Nginx)
# =============================================================================
FROM nginx:alpine AS runner

# Remove default nginx config
RUN rm /etc/nginx/conf.d/default.conf

# Copy custom nginx configuration
COPY nginx.conf /etc/nginx/conf.d/

# Copy built assets from builder stage
COPY --from=builder /app/dist /usr/share/nginx/html

# Add non-root user capabilities
RUN chown -R nginx:nginx /usr/share/nginx/html && \
    chown -R nginx:nginx /var/cache/nginx && \
    chown -R nginx:nginx /var/log/nginx && \
    touch /var/run/nginx.pid && \
    chown -R nginx:nginx /var/run/nginx.pid

# Expose port 80
EXPOSE 80

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:80/health || exit 1

# Start nginx
CMD ["nginx", "-g", "daemon off;"]
```

```nginx nginx.conf
server {
    listen 80;
    server_name localhost;
    root /usr/share/nginx/html;
    index index.html;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied expired no-cache no-store private auth;
    gzip_types text/plain text/css text/xml text/javascript application/x-javascript application/xml application/javascript;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # Health check endpoint
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }

    # Static assets with long cache
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
        try_files $uri =404;
    }

    # SPA routing - serve index.html for all routes
    location / {
        try_files $uri $uri/ /index.html;
    }

    # API proxy (if needed)
    location /api/ {
        proxy_pass http://backend:3000/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
}
```

</CodeGroup>

## Full Stack Docker Compose

### Local Development Stack

Complete Docker Compose for running the full stack locally.

<CodeGroup>

```yaml docker-compose.yml
version: '3.8'

services:
  # ==========================================================================
  # Database
  # ==========================================================================
  postgres:
    image: postgres:17
    container_name: vritti-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-localdev}
      POSTGRES_DB: ${POSTGRES_DB:-saas_db}
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - vritti-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================================================
  # Backend API
  # ==========================================================================
  backend:
    build:
      context: ./vritti-api-nexus
      dockerfile: Dockerfile
    container_name: vritti-backend
    restart: unless-stopped
    environment:
      NODE_ENV: development
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-localdev}@postgres:5432/${POSTGRES_DB:-saas_db}
      JWT_SECRET: ${JWT_SECRET:-your-jwt-secret-here}
      PORT: 3000
    ports:
      - "3000:3000"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - vritti-network
    volumes:
      - ./vritti-api-nexus:/app
      - /app/node_modules
    command: pnpm dev

  # ==========================================================================
  # Frontend Web App
  # ==========================================================================
  frontend:
    build:
      context: ./vritti-web-nexus
      dockerfile: Dockerfile
      args:
        VITE_API_URL: http://localhost:3000
    container_name: vritti-frontend
    restart: unless-stopped
    ports:
      - "8080:80"
    depends_on:
      - backend
    networks:
      - vritti-network

  # ==========================================================================
  # Redis (Optional - for caching/sessions)
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: vritti-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - vritti-network
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  vritti-network:
    driver: bridge
    name: vritti-network

volumes:
  pgdata:
    name: vritti-pgdata
  redis-data:
    name: vritti-redis-data
```

```yaml docker-compose.override.yml
# Development overrides - hot reloading and debugging
version: '3.8'

services:
  backend:
    build:
      target: deps
    volumes:
      - ./vritti-api-nexus/src:/app/src
      - ./vritti-api-nexus/package.json:/app/package.json
    command: pnpm dev
    environment:
      DEBUG: "nestjs:*"

  frontend:
    build:
      context: ./vritti-web-nexus
      target: deps
    volumes:
      - ./vritti-web-nexus/src:/app/src
      - ./vritti-web-nexus/public:/app/public
    ports:
      - "5173:5173"
    command: pnpm dev --host 0.0.0.0
```

</CodeGroup>

### Production Stack

<CodeGroup>

```yaml docker-compose.prod.yml
version: '3.8'

services:
  postgres:
    image: postgres:17
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - vritti-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  backend:
    image: ${REGISTRY}/vritti-backend:${TAG:-latest}
    restart: always
    environment:
      NODE_ENV: production
      DATABASE_URL: ${DATABASE_URL}
      JWT_SECRET: ${JWT_SECRET}
      PORT: 3000
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - vritti-network
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  frontend:
    image: ${REGISTRY}/vritti-frontend:${TAG:-latest}
    restart: always
    depends_on:
      - backend
    networks:
      - vritti-network
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  nginx:
    image: nginx:alpine
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    networks:
      - vritti-network

networks:
  vritti-network:
    driver: bridge

volumes:
  pgdata:
```

</CodeGroup>

## Docker Networking

### Network Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     vritti-network                          │
│                                                             │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   nginx     │───▶│  frontend   │    │   redis     │     │
│  │   :80/:443  │    │    :80      │    │   :6379     │     │
│  └──────┬──────┘    └─────────────┘    └─────────────┘     │
│         │                                     ▲             │
│         │           ┌─────────────┐           │             │
│         └──────────▶│   backend   │───────────┘             │
│                     │   :3000     │                         │
│                     └──────┬──────┘                         │
│                            │                                │
│                     ┌──────▼──────┐                         │
│                     │  postgres   │                         │
│                     │   :5432     │                         │
│                     └─────────────┘                         │
└─────────────────────────────────────────────────────────────┘
```

### Service Discovery

Within the Docker network, services can communicate using their service names:

```bash
# From backend container
DATABASE_URL=postgresql://postgres:password@postgres:5432/saas_db
REDIS_URL=redis://redis:6379

# From frontend nginx
proxy_pass http://backend:3000/;
```

### Exposing Ports

| Service  | Internal Port | External Port | Purpose |
|----------|--------------|---------------|---------|
| postgres | 5432 | 5432 | Database access |
| backend | 3000 | 3000 | API access |
| frontend | 80 | 8080 | Web app access |
| redis | 6379 | 6379 | Cache access |

## Volume Management

### Named Volumes

Named volumes persist data across container restarts and are managed by Docker.

```yaml
volumes:
  pgdata:
    name: vritti-pgdata       # Explicit name for easier management
  redis-data:
    name: vritti-redis-data
```

### Volume Operations

```bash
# List all volumes
docker volume ls

# Inspect a volume
docker volume inspect vritti-pgdata

# Remove unused volumes
docker volume prune

# Backup PostgreSQL data
docker run --rm \
  -v vritti-pgdata:/data \
  -v $(pwd):/backup \
  alpine tar czf /backup/pgdata-backup.tar.gz /data

# Restore PostgreSQL data
docker run --rm \
  -v vritti-pgdata:/data \
  -v $(pwd):/backup \
  alpine tar xzf /backup/pgdata-backup.tar.gz -C /
```

### Bind Mounts for Development

Use bind mounts in development for hot reloading:

```yaml
services:
  backend:
    volumes:
      # Bind mount source code
      - ./vritti-api-nexus/src:/app/src
      # Anonymous volume for node_modules (prevents overwrite)
      - /app/node_modules
```

<Warning>
Never use bind mounts in production. Always copy files into the image during build.
</Warning>

## Environment Variable Handling

### Development Environment

Create a `.env` file in the project root:

```bash .env
# Database
POSTGRES_USER=postgres
POSTGRES_PASSWORD=localdev
POSTGRES_DB=saas_db

# Backend
JWT_SECRET=your-development-secret
NODE_ENV=development
DATABASE_URL=postgresql://postgres:localdev@localhost:5432/saas_db

# Frontend
VITE_API_URL=http://localhost:3000
VITE_APP_ENV=development
```

### Using Environment Files

```yaml docker-compose.yml
services:
  backend:
    env_file:
      - .env
      - .env.local  # Override with local settings
    environment:
      # Explicit overrides take precedence
      NODE_ENV: development
```

### Production Environment Variables

<Warning>
Never commit production secrets to version control. Use a secrets manager.
</Warning>

Options for production secrets:

1. **Docker Secrets** (Swarm mode):
```yaml
services:
  backend:
    secrets:
      - db_password
      - jwt_secret

secrets:
  db_password:
    external: true
  jwt_secret:
    external: true
```

2. **Environment variable injection** at deployment:
```bash
docker run -e DATABASE_URL="$DATABASE_URL" -e JWT_SECRET="$JWT_SECRET" vritti-backend
```

3. **External secrets manager** (recommended):
```yaml
# Use tools like HashiCorp Vault, AWS Secrets Manager, etc.
environment:
  - DATABASE_URL=${DATABASE_URL}  # Injected by CI/CD
```

### Build-time vs Runtime Variables

```dockerfile
# Build-time arguments (embedded in image)
ARG VITE_API_URL
ENV VITE_API_URL=$VITE_API_URL

# Runtime variables (set when container starts)
# These are NOT available during build
ENV NODE_ENV=production
```

## Build Optimization

### 1. Layer Caching

Order Dockerfile instructions from least to most frequently changed:

```dockerfile
# Good: Dependencies change less often than source code
COPY package.json pnpm-lock.yaml ./
RUN pnpm install --frozen-lockfile

# Source code changes frequently - copy last
COPY . .
RUN pnpm build
```

### 2. Multi-stage Builds

Reduce final image size by only including necessary files:

```dockerfile
# Build stage includes devDependencies
FROM node:22-alpine AS builder
RUN pnpm install
RUN pnpm build

# Production stage only has what's needed
FROM node:22-alpine AS runner
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
```

### 3. .dockerignore

Create a `.dockerignore` to exclude unnecessary files:

```text .dockerignore
# Dependencies
node_modules
.pnpm-store

# Build outputs
dist
build
.next

# Development files
.git
.gitignore
*.md
.env*
.vscode
.idea

# Test files
coverage
*.test.ts
*.spec.ts
__tests__

# Logs
*.log
npm-debug.log*

# OS files
.DS_Store
Thumbs.db
```

### 4. Alpine Base Images

Use Alpine-based images for smaller size:

```dockerfile
# Full Node.js image: ~1GB
FROM node:22

# Alpine variant: ~150MB
FROM node:22-alpine
```

### 5. BuildKit Features

Enable BuildKit for faster builds:

```bash
# Enable BuildKit
export DOCKER_BUILDKIT=1

# Or in docker-compose
COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1 docker compose build
```

### 6. Parallel Builds

Build multiple services simultaneously:

```bash
# Build all services in parallel
docker compose build --parallel

# Or with BuildKit
docker buildx bake --file docker-compose.yml
```

### Image Size Comparison

| Configuration | Backend Size | Frontend Size |
|--------------|--------------|---------------|
| Single stage, full node | ~1.2GB | ~800MB |
| Multi-stage, full node | ~400MB | ~150MB |
| Multi-stage, alpine | ~180MB | ~25MB |

## Quick Reference

### Common Commands

```bash
# Build and start all services
docker compose up --build

# Start in detached mode
docker compose up -d

# View logs
docker compose logs -f backend

# Stop all services
docker compose down

# Stop and remove volumes
docker compose down -v

# Rebuild a specific service
docker compose build backend

# Execute command in running container
docker compose exec backend sh

# Run one-off command
docker compose run --rm backend pnpm db:migrate
```

### Troubleshooting

```bash
# Check container status
docker compose ps

# View container logs
docker compose logs backend --tail=100

# Inspect network
docker network inspect vritti-network

# Check volume mounts
docker inspect vritti-backend | jq '.[0].Mounts'

# Enter container for debugging
docker compose exec backend sh
```

## Related Resources

<CardGroup cols={2}>
  <Card title="Environment Setup" icon="gear" href="/getting-started/environment-setup">
    Local development environment configuration
  </Card>
  <Card title="CI/CD Pipeline" icon="rotate" href="/operations/ci-cd">
    Automated build and deployment pipelines
  </Card>
  <Card title="Production Deployment" icon="server" href="/operations/deployment/production">
    Production infrastructure and deployment
  </Card>
  <Card title="Monitoring" icon="chart-line" href="/operations/monitoring">
    Container and application monitoring
  </Card>
</CardGroup>
